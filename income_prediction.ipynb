{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income Prediction based on U.S. Census data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Info\n",
    "\n",
    "<b>Materials</b>: See [Using Jupyter Notebook and Python page](https://canvas.lms.unimelb.edu.au/courses/105477/pages/python-and-jupyter-notebooks?module_item_id=2613813) on Canvas (under Modules>Resources) for information on the basic setup required for this class, including an iPython notebook viewer and some handy python packages including Numpy, Scipy, Matplotlib, Scikit-Learn, and Gensim. You can use any Python built-in packages, but do not use any other 3rd party packages (the packages listed above are all fine to use); if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it. While the main focus is on correctness of your methods, you will lose marks if your code is not understandable.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on the discussion board; we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. We will be checking submissions for originality and will invoke the Universityâ€™s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment, you will be working with the famous *Adult* a data set containing demographic and income data from the united states in 1994. The dataset provided for this assignment is derived from <a href=\"http://archive.ics.uci.edu/ml/datasets/Adult\">this</a> resource. The data set consists of about 48,000 individuals each characterized through a set of 14 attributes. Your task is to predict whether the individual earns up to \\\\$ 50,000 a year (<=50K) or more than \\\\$50,000 per year (>50K).\n",
    "\n",
    "The attributes are\n",
    "\n",
    "|ID|Feature Name| Feature Type | Feature Values|\n",
    "| :-| :-| :-| :-|\n",
    "|0|age| continuous| |\n",
    "|1|workclass| categorical | Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, ?|\n",
    "|2|fnlwgt| continuous| |\n",
    "|3|education|  categorical |Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool|\n",
    "|4|education-num| continuous| |\n",
    "|5|marital-status|  categorical |Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse|\n",
    "|6|occupation|  categorical |Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces, ?|\n",
    "|7|relationship|  categorical |Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried|\n",
    "|8|race|  categorical |White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black|\n",
    "|9|sex|  categorical |Female, Male|\n",
    "|10|capital-gain| continuous| |\n",
    "|11|capital-loss| continuous| |\n",
    "|12|hours-per-week| continuous| |\n",
    "|13|native-country|  categorical |United-States, Cambodia, England, Puerto-Rico, Canada, Germany, India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, ?|\n",
    "\n",
    "You can find out more about the individual attributes / values, and the origin of the data set in the <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\"> data set description</a>  \n",
    "\n",
    "\n",
    "You will build a number of classifiers to predict the income class based on the attributes above.\n",
    "\n",
    "\n",
    "#### The following instructions hold for every question in the assignment\n",
    "- leave the order of instances intact, i.e., do not shuffle the data\n",
    "- do not change the names or types of variables provided by us in the code cells below\n",
    "- '?' denotes an unknown value, and you should treat it as just another value for its feature in all tasks below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Loading and pre-processing the data\n",
    "\n",
    "You were provide two data files:\n",
    "\n",
    "**adult.train** contains about 32,000 training instances, one instance per line in comma-separated value (csv) format. Each line contains 14 fields. The first 13 fields correspond to the features listed above, the final field denotes the class label\n",
    "\n",
    "**adult.test** is formatted exactly like adult.train, and contains about 16,000 further instances for evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a Read the data\n",
    "First, you will read in the data and create traing features, training labels, test features and test labels. Do not apply any data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32525, 32525, 16262, 16262, 14, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "\n",
    "data = open(\"adult.train\",'r').readlines()\n",
    "test_data = open(\"adult.test\",'r').readlines()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "############################\n",
    "## your code begins here\n",
    "############################\n",
    "ft_train = []\n",
    "ft_test = []\n",
    "\n",
    "#helper function to clean all spaces from dataset\n",
    "def remove_space(data): \n",
    "        if type(data) is str:\n",
    "                return data.replace(\" \",\"\")\n",
    "        else:\n",
    "            for d in data:\n",
    "                    return [remove_space(d) for d in data]\n",
    "                \n",
    "for line in data:\n",
    "        dt = line.strip().split(\",\")\n",
    "        ft_train.append(dt[:-1]) \n",
    "        y_train.append(dt[-1].strip())\n",
    "    \n",
    "for line in test_data:\n",
    "        t_dt = line.strip().split(\",\")\n",
    "        ft_test.append(t_dt[:-1]) \n",
    "        y_test.append(t_dt[-1].strip())\n",
    "        \n",
    "x_train = remove_space(ft_train)\n",
    "x_test = remove_space(ft_test)\n",
    "        \n",
    "\n",
    "############################\n",
    "## your code ends here\n",
    "############################\n",
    "\n",
    "len(x_train), len(y_train), len(x_test), len(y_test), len(x_train[0]), len(x_test[0])\n",
    "#print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(x_train)==len(y_train)==32525\n",
    "assert len(x_train[0])==len(x_test[0])==14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: Attribute Types\n",
    "\n",
    "You will create three feature representations, based on the different attribute types (categorical, numeric) in the original *Adult* data.\n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "Denote with $I$ the number of training instances; $N$ the number of numeric features in the data set; and $v_f$ the number of possible values for feature $f$.\n",
    "\n",
    "1. Create a train data set with only numeric features `x_train_num` (size $(I\\times N)$); and equivaluently a test data set `x_test_num`\n",
    "2. Create a train data set with only categorical features *in a 1-hot representation* `x_train_1hot` (size $(I\\times\\sum_f v_f)$); and equivalently a test data set `x_test_1hot`\n",
    "3. Create a train data set with both numeric and 1-hot categorical features `x_train_full` (size $I \\times N+\\sum_f v_f$) where the first $N$ columns represent the numerical features and the remaining columns the categorical features; and equivalently a test data set `x_test_full`\n",
    "\n",
    "**Note:** You may use classes and functions from ```scikit-learn```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num = []\n",
    "x_test_num = []\n",
    "\n",
    "x_train_1hot = []\n",
    "x_test_1hot = []\n",
    "\n",
    "x_train_full = []\n",
    "x_test_full = []\n",
    "\n",
    "################################\n",
    "### Your code begins here ######\n",
    "################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Columns_x = ('age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "           'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', \n",
    "           'native-country')\n",
    "\n",
    "Columns_y = 'income-level'\n",
    "\n",
    "Numeric_columns = ('age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week')\n",
    "\n",
    "Categorial_columns = ('workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', \n",
    "                      'sex', 'native-country')\n",
    "\n",
    "#####transfer train & test data into pandas DataFrame for further usage#####\n",
    "df_x_train = pd.DataFrame(x_train, columns=list(Columns_x))  #train_features\n",
    "df_y_train = pd.DataFrame(y_train, columns=[Columns_y])  #train_labels\n",
    "\n",
    "df_x_test = pd.DataFrame(x_test, columns=list(Columns_x))   #test_features\n",
    "df_y_test = pd.DataFrame(y_test, columns=[Columns_y])   #test_labels\n",
    "\n",
    "#numeric features using pandas\n",
    "x_train_num = df_x_train[list(Numeric_columns)].values.tolist()\n",
    "x_test_num = df_x_test[list(Numeric_columns)].values.tolist()\n",
    "\n",
    "#one-hot using pandas\n",
    "pre_x_1hot_train = pd.DataFrame(df_x_train, columns = list(Categorial_columns))#dataframe contains Categorial_columns\n",
    "pre_x_1hot_test = pd.DataFrame(df_x_test, columns = list(Categorial_columns))#dataframe contains Categorial_columns\n",
    "\n",
    "a_train = pd.get_dummies(pre_x_1hot_train, columns = list(Categorial_columns))\n",
    "a_test = pd.get_dummies(pre_x_1hot_test, columns = list(Categorial_columns))\n",
    "\n",
    "x_train_1hot = a_train.values.tolist()\n",
    "x_test_1hot = a_test.values.tolist()\n",
    "#print(x_train_1hot[0])\n",
    "\n",
    "#both numeric and 1-hot categorical features\n",
    "\n",
    "for i in range(0, len(x_train_num)):\n",
    "    xtf = x_train_num[i] + x_train_1hot[i]\n",
    "    x_train_full.append(xtf)\n",
    "    \n",
    "for i in range(0, len(x_test_num)):\n",
    "    xtf_1 = x_test_num[i] + x_test_1hot[i]\n",
    "    x_test_full.append(xtf_1)\n",
    "\n",
    "################################\n",
    "### Your code ends here ########\n",
    "################################\n",
    "\n",
    "#print(x_train_1hot[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> For your testing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(x_train_1hot[0])==98\n",
    "assert len(x_train_full[0])==104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: A 0-R baseline\n",
    "\n",
    "Implement a zero-r baseline, as introduced in the Evaluation lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The marority class is: <=50K\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "majority_class = \"\"\n",
    "zero_r_predictions = []\n",
    "\n",
    "############################\n",
    "## your code begins here\n",
    "############################\n",
    "majority_class = max(set(y_train), key=y_train.count)\n",
    "\n",
    "zero_r_predictions = [majority_class for i in range(len(y_test))]\n",
    "\n",
    "############################\n",
    "## your code ends here\n",
    "############################\n",
    "\n",
    "print(f\"The marority class is: {majority_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Feature selection\n",
    "\n",
    "In this question you will implement pointwise mutual information (PMI) for feature selection (Question 3a)\n",
    "\n",
    "In question 3a. you will use the implemented function to create a 1-R classifier based on the single 1-hot attribute  (i.e., categorical feature value) with highest PMI for class \">50K\". \n",
    "```\n",
    "argmax_a pmi(a=1,c=\">50K\")\n",
    "```\n",
    "In question 3b. you will apply your 1-R classifier to the test instances, and store your predicted labels in `one_r_predictions`.\n",
    "\n",
    "<b> You should implement PMI from scratch yourself. You may use native Python libraries like math or numpy to help you, but you may not use existing implementations of PMI.</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Implement PMI\n",
    "\n",
    "Implement a function to compute PMI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PMI: A function to compute the pointwise mutual information between \n",
    "all features in the data set and a target class of interest\n",
    "Input: - features for N input instances\n",
    "       - labels for N input instances\n",
    "       - target feature value (default=1)\n",
    "       - target class (fdefault='>50K')\n",
    "Output: a dictionary of the form {feature: ppmi} where each \n",
    "        feature is denoted by its ID (position in the 1-hot encoded representatoin)\n",
    "\n",
    "'''\n",
    "\n",
    "############################\n",
    "## your code begins here\n",
    "############################\n",
    "import math\n",
    "import sys\n",
    "\n",
    "def pmi(features, labels, tgt_value=1, tgt_class=\">50K\"):\n",
    "    pmis = {}\n",
    "           \n",
    "    helper_lst = extract_elem(features)\n",
    "    \n",
    "    #calculate P(A) - features\n",
    "    p_a = []\n",
    "    p_a = calculate_p(helper_lst, tgt_value)\n",
    "    #print(p_a)\n",
    "\n",
    "    #P(C) - labels\n",
    "    lenth_c = len(labels)\n",
    "    count=0\n",
    "    for elem in labels:\n",
    "        if elem == tgt_class:\n",
    "            count+=1\n",
    "    p_c = count/lenth_c\n",
    "\n",
    "    #P(A,C) - joint probabilities\n",
    "    p_ac = []\n",
    "    \n",
    "    for row in helper_lst:\n",
    "        count_jc = 0\n",
    "        for i in range(0,len(row)):\n",
    "            if row[i] == tgt_value and labels[i] == tgt_class:\n",
    "                count_jc += 1\n",
    "        p_ac.append(count_jc/len(features))\n",
    "\n",
    "    #indexes in helper_lst are the keys for pmis\n",
    "\n",
    "    for i in range(0, len(helper_lst)):\n",
    "        #print(type((p_ac.get(i)/(p_a.get(i)*p_c))))\n",
    "        if (p_ac[i]/(p_a[i]*p_c)) == 0:\n",
    "            \n",
    "            pmis[i] = math.inf  # = 0\n",
    "            \n",
    "        else:                       \n",
    "            pmis[i] = math.log((p_ac[i]/(p_a[i]*p_c)), 2) ##avoid devide by zero    \n",
    "        \n",
    "    return pmis\n",
    "\n",
    "#Helper function to calculate probability\n",
    "def calculate_p(FL_list, tgt_value):\n",
    "    p = [] #dictionary using index of features list as key.\n",
    "    for row in FL_list:\n",
    "        count = 0\n",
    "        for elem in row:\n",
    "            if elem == tgt_value:\n",
    "                count += 1\n",
    "        p.append(count/len(row))\n",
    "    #print('this is p')\n",
    "    #print(p)\n",
    "    #print(list(p.values()))\n",
    "    return p\n",
    "\n",
    "def extract_elem(lst):\n",
    "    new_lst = []\n",
    "    for i in range(0, len(lst[0])):\n",
    "        new_lst.append([item[i] for item in lst])\n",
    "    return new_lst\n",
    "\n",
    "############################\n",
    "## your code ends here\n",
    "############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = [[1,1], [1,0], [0,1], [0,0]]\n",
    "test_labels = [1,1,0,0]\n",
    "test_pmi = pmi(test_features, test_labels, tgt_class=1)\n",
    "\n",
    "# where the index 0 refers to \"feature 1\" and index 1 refers to \"feature 2\"\n",
    "assert test_pmi[0]==1.0\n",
    "assert test_pmi[1]==0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b Create 1-R baseline\n",
    "\n",
    "- Apply your PMI function to the *1_hot feature representation* of training data, and determine the (i) 1-hot feature with *highest* PMI with class '>50K' () and (ii) 1-hot feature with *lowest* (most negative) PMI with class '>50K'. Store the name (string) of the corresponding highest/lowest PMI features in `highest_pmi_feature_name` and `lowest_pmi_feature_name`, respectively.\n",
    "\n",
    "- The feature with *highest* PMI will consitute your 1-R predictor, which you should use to predict the class labels for the test set (`one_r_predictions`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K', '<=50K', '<=50K', '<=50K', '<=50K', '<=50K', '<=50K', '<=50K', '<=50K', '<=50K']\n",
      "The feature with highest PMI for the class '>50K' is: workclass\n",
      "The feature with lowest PMI for the class '>50K' is: native-country\n"
     ]
    }
   ],
   "source": [
    "one_r_predictions = []\n",
    "\n",
    "highest_pmi_feature_name = \"\" # feature with highest PMI\n",
    "lowest_pmi_feature_name = \"\" # feature with lowest PMI\n",
    "\n",
    "############################\n",
    "## your code begins here\n",
    "############################\n",
    "Categorial_list = list(Categorial_columns)\n",
    "#('workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country')\n",
    "feature_names = []  #total 98 names\n",
    "features_count = {} #dictionary stores 8 {Categorial_feature:count}\n",
    "pmi_aggregate = {} #dictionary stores 8 {Categorial_feature:pmi}\n",
    "    \n",
    "def obtain_1r_ftNames(catg_train_data):\n",
    "    lst = []\n",
    "    for col in catg_train_data:\n",
    "        lst.append(col)\n",
    "    #print(lst)\n",
    "    return lst\n",
    "\n",
    "#print(type(feature_names[0]))\n",
    "def counter_tool(lst, substring):\n",
    "    count_f = 0 \n",
    "    for elem in lst:\n",
    "        if substring in elem:\n",
    "            count_f+=1\n",
    "    return count_f\n",
    "\n",
    "def count_ft(feature_names_lst):\n",
    "    d = {}\n",
    "    for item in Categorial_columns:\n",
    "        num = counter_tool(feature_names_lst, item)\n",
    "        d[item] = num\n",
    "    return d\n",
    "\n",
    "#calculate aggregate pmi for each     \n",
    "def pmi_cal(lst, substring, pmis_dict):\n",
    "    pmi_sum = 0\n",
    "    for elem in lst:\n",
    "        if substring in elem:\n",
    "            pmi_sum += pmis_dict[lst.index(elem)]\n",
    "    return pmi_sum\n",
    "\n",
    "def pmi_aggr(One_R_pmis):\n",
    "    pmi_dic={}\n",
    "    for item in Categorial_columns:\n",
    "        num = pmi_cal(feature_names, item, One_R_pmis)\n",
    "    #print(num)\n",
    "        pmi_dic[item] = num\n",
    "    return pmi_dic\n",
    "\n",
    "def max_name(pmi_aggr_dict):\n",
    "    m_name = max(pmi_aggr_dict, key = pmi_aggr_dict.get)\n",
    "    return m_name\n",
    "\n",
    "#dictionary stores {Categorial_subfeatures:pmi}\n",
    "pmis = pmi(x_train_1hot, y_train)\n",
    "\n",
    "#a list of Categorial names for all 98 sub-features\n",
    "feature_names = obtain_1r_ftNames(a_train) #pre_x_1hot_train check Question 1-b\n",
    "\n",
    "#dictionary stores sum_pmi group by Categorial_feature names\n",
    "pmi_aggregate = pmi_aggr(pmis) \n",
    "#print(pmi_aggregate)\n",
    "\n",
    "#dictionary stores 8 {Categorial_feature:count(how many sub_features)}\n",
    "features_count = count_ft(feature_names)\n",
    "\n",
    "#Categorial feature name with highest/lowest pmi\n",
    "highest_pmi_feature_name = max_name(pmi_aggregate)  \n",
    "lowest_pmi_feature_name = min(pmi_aggregate, key = pmi_aggregate.get)\n",
    "\n",
    "#find the (train/test) feature with highest PMI, extract 'workclass' column\n",
    "feature_Hpmi = df_x_train[highest_pmi_feature_name].values.tolist()\n",
    "#print(feature_Hpmi)\n",
    "x_test_Hpmi = df_x_test[highest_pmi_feature_name].values.tolist()\n",
    "\n",
    "#use y_train as train labels\n",
    "\n",
    "#find sub-feature names under 'highest_pmi_feature_name'\n",
    "def find_pattern(features_count_dict, high_feature_name, catg_feature_names):\n",
    "    p=[]\n",
    "    for i in range(features_count_dict[high_feature_name]):\n",
    "        p.append(catg_feature_names[i][len(high_feature_name)+1:])\n",
    "    return p\n",
    "\n",
    "highest_sub_features = find_pattern(features_count, highest_pmi_feature_name, feature_names)\n",
    "#print(highest_sub_features)\n",
    "\n",
    "def label_predict(patterns, single_feature_raw_data, single_feature_labels, test_data): #returns a list of 1-r labels under each sub features\n",
    "    label_predict = []\n",
    "    final_predict = []\n",
    "\n",
    "    for wc in patterns:\n",
    "        a = [] \n",
    "        labels = [] \n",
    "        for i in range(len(single_feature_raw_data)):\n",
    "            if single_feature_raw_data[i] == wc:\n",
    "                labels.append(single_feature_labels[i])\n",
    "        a.append(max(set(labels), key=labels.count)) \n",
    "        #print(a)\n",
    "        label_predict += a\n",
    "#print(label_predict)\n",
    "\n",
    "    for item in test_data:\n",
    "        for wc in patterns:\n",
    "            if item == wc:\n",
    "                final_predict.append(label_predict[patterns.index(wc)])\n",
    "                \n",
    "    return final_predict\n",
    "\n",
    "one_r_predictions = label_predict(highest_sub_features, feature_Hpmi, y_train, x_test_Hpmi)\n",
    "\n",
    "\n",
    "############################\n",
    "## your code ends here\n",
    "############################\n",
    "\n",
    "print(one_r_predictions[:10])\n",
    "print(f\"The feature with highest PMI for the class '>50K' is: {highest_pmi_feature_name}\")\n",
    "print(f\"The feature with lowest PMI for the class '>50K' is: {lowest_pmi_feature_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Naive Bayes\n",
    "\n",
    "We will construct three Naive Bayes classifiers\n",
    "\n",
    "1. One for instances with only 1-hot encoded (binary) categorical attributes.\n",
    "2. One for instances with only numerical attributes.\n",
    "3. One for instances with the full set of numerical *and* categorical attributes, ensuring that your classifier computes posterior class probabilities $p(y|x)$ as $p(x|y)p(y)$.\n",
    "\n",
    "For each classifier, you will \n",
    "1. Train it on the training set\n",
    "2. Use the models to predict labels for the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a Implementing the Naive Bayes classifiers\n",
    "\n",
    "Implement three functions which train a NB classifier given the specified input feature types and predict labels for a given test set.\n",
    "\n",
    "You may add additional quantities to your `return` statements.\n",
    "\n",
    "<b> You may (and are, indeed, encouraged) to, use the existing NB implementations from `sklearn`. You should use the default parameterizations of these algorithms.</b> \n",
    "    \n",
    "If you choose to implement your classifiers from scratch, please use Laplace smoothing (alpha=1) for the categorical feature NB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################\n",
    "## your code begins here\n",
    "##################################\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def nb_binary_features(train_features, train_labels, test_features):  #1-hot\n",
    "    predictions = []\n",
    "\n",
    "    brn = BernoulliNB()\n",
    "    brn.fit(train_features, train_labels)\n",
    "    \n",
    "    predictions = brn.predict(test_features).tolist()\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def nb_continuous_features(train_features, train_labels, test_features): #numeric\n",
    "    predictions = []\n",
    "    \n",
    "    gn = GaussianNB()\n",
    "    gn.fit(train_features, train_labels)\n",
    "    \n",
    "    predictions = gn.predict(test_features).tolist()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def nb_full(train_features, train_labels, test_features):   #full \n",
    "    predictions = []\n",
    "    \n",
    "    #split arrays into two parts: num & one-hot part\n",
    "    lenth = len(Numeric_columns)\n",
    "    indices_num = [i for i in range(lenth)]\n",
    "    indices_1hot = [i for i in range(lenth, len(train_features[0]))]\n",
    "    #print(indices_1hot)\n",
    "    \n",
    "    num_x_train=[]\n",
    "    num_x_test = []\n",
    "    \n",
    "    for item in train_features:\n",
    "        num_x_train.append(item[indices_num])\n",
    "        \n",
    "    for item in test_features:\n",
    "        num_x_test.append(item[indices_num])\n",
    "\n",
    "    #print(num_x_test[:10])\n",
    "    hot_x_train=[]\n",
    "    hot_x_test = []\n",
    "    \n",
    "    for item in train_features:\n",
    "        hot_x_train.append(item[indices_1hot])\n",
    "        \n",
    "    for item in test_features:\n",
    "        hot_x_test.append(item[indices_1hot])\n",
    "    \n",
    "    brn = BernoulliNB()\n",
    "    brn.fit(hot_x_train, train_labels)\n",
    "    brn_predict = brn.predict(hot_x_test)\n",
    "    proba_brn = brn.predict_proba(hot_x_test)\n",
    "    \n",
    "    gn = GaussianNB()\n",
    "    gn.fit(num_x_train, train_labels)\n",
    "    gn_predict = gn.predict(num_x_test)\n",
    "    proba_gn = gn.predict_proba(num_x_test)\n",
    "\n",
    "    proba_brn_1 = []\n",
    "    proba_brn_2 = []\n",
    "    \n",
    "    proba_gn_1 = []\n",
    "    proba_gn_2 = []\n",
    "    \n",
    "    for item in proba_brn:\n",
    "        proba_brn_1.append(item[0])\n",
    "        proba_brn_2.append(item[1])\n",
    "        \n",
    "    for item in proba_gn:\n",
    "        proba_gn_1.append(item[0])\n",
    "        proba_gn_2.append(item[1])\n",
    "        \n",
    "    aggr_proba_1 = [a * b for a, b in zip(proba_brn_1, proba_gn_1)]\n",
    "    aggr_proba_2 = [a * b for a, b in zip(proba_brn_2, proba_gn_2)]\n",
    "    \n",
    "    for i in range(len(aggr_proba_1)):\n",
    "        if aggr_proba_1[i] > aggr_proba_2[i]:\n",
    "            predictions.append('<=50K')\n",
    "        else:\n",
    "            predictions.append('>50K')\n",
    "    #print(len(predictions))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "############################\n",
    "## your code ends here\n",
    "############################\n",
    "#x_train_full_1 = np.array(x_train_full)\n",
    "#x_train_full_1 = x_train_full_1.astype('int')\n",
    "#x_test_full_1 = np.array(x_test_full)\n",
    "#x_test_full_1 = x_test_full_1.astype('int')\n",
    "#nb_full(x_train_full_1, y_train, x_test_full_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b Apply your classifiers to the data sets you created in Questions 1 and 3b\n",
    "\n",
    "...namely, the\n",
    "\n",
    "1. 1-hot categorical features `x_{train,test}_1hot`\n",
    "2. numerical features `x_{train,test}_num`\n",
    "3. combined numerical and 1-hot categorical features `x_{train,test}_full`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical NB predicted class distribution \t Counter({'<=50K': 14440, '>50K': 1822})\n",
      "Categorical NB predicted class distribution\t Counter({'<=50K': 10046, '>50K': 6216})\n",
      "Full NB predicted class distribution\t Counter({'<=50K': 13393, '>50K': 2869})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "############################\n",
    "## your code begins here\n",
    "############################\n",
    "\n",
    "x_train_num_1 = np.array(x_train_num)\n",
    "x_train_num_1 = x_train_num_1.astype('int')\n",
    "x_test_num_1 = np.array(x_test_num)\n",
    "x_test_num_1 = x_test_num_1.astype('int')\n",
    "#print(type(x_train_num_1))\n",
    "\n",
    "x_train_full_1 = np.array(x_train_full)\n",
    "x_train_full_1 = x_train_full_1.astype('int')\n",
    "x_test_full_1 = np.array(x_test_full)\n",
    "x_test_full_1 = x_test_full_1.astype('int')\n",
    "\n",
    "categorical_nb_predictions = nb_binary_features(a_train, y_train, a_test)\n",
    "numeric_nb_predictions = nb_continuous_features(x_train_num_1, y_train, x_test_num_1)\n",
    "full_nb_predictions = nb_full(x_train_full_1, y_train, x_test_full_1)\n",
    "\n",
    "#print(a_test)\n",
    "############################\n",
    "## your code ends here\n",
    "############################\n",
    "\n",
    "print(f\"Numerical NB predicted class distribution \\t {Counter(numeric_nb_predictions)}\")\n",
    "print(f\"Categorical NB predicted class distribution\\t {Counter(categorical_nb_predictions)}\")\n",
    "print(f\"Full NB predicted class distribution\\t {Counter(full_nb_predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Logistic Regression\n",
    "\n",
    "Apply a Logistic Regression classifier to the full training data set (`x_{train,test}_full`)\n",
    "\n",
    "<b> Use the existing implementation in sklearn with default parameters. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a The Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR predicted class distribution\t Counter({'<=50K': 14837, '>50K': 1425})\n",
      "\n",
      "\n",
      "pmi values in Q3: {'workclass': 1.2450527236150353, 'education': -10.54470295370337, 'marital-status': -6.814652064391762, 'occupation': -12.325804989323599, 'relationship': -8.13279966987268, 'race': -3.172058817071518, 'sex': -0.7928749299032869, 'native-country': -20.394740371340824}\n",
      "\n",
      "\n",
      "coefficient values in Q5a: {'age': -0.007213875579054285, 'fnlwgt': -3.7328651002938924e-06, 'education-num': -0.0016782596410539507, 'capital-gain': 0.00033945995638995797, 'capital-loss': 0.0007809628903499234, 'hours-per-week': -0.007925726398248574, 'workclass': -0.00035576358532378476, 'education': -0.00035576358532391134, 'marital-status': -0.00035576358532371294, 'occupation': -0.00035576358532383973, 'relationship': -0.00035576358532409284, 'race': -0.00035576358532390614, 'sex': -0.0003557635853237865, 'native-country': -0.0003557635853238577}\n",
      "\n",
      "\n",
      "The feature with the largest coefficients is: capital-loss\n",
      "The feature with the second largest coefficients is capital-gain\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_predictions = []\n",
    "\n",
    "############################\n",
    "## your code begins here\n",
    "############################\n",
    "lreg = LogisticRegression()\n",
    "\n",
    "lreg.fit(x_train_full_1, y_train)\n",
    "lr_predictions = lreg.predict(x_test_full_1)\n",
    "\n",
    "#Q5b\n",
    "#coefficients (weights) learnt by the classifier\n",
    "coefficients = lreg.coef_.ravel()\n",
    "#compare them to the PMI values in Question 3\n",
    "#find features with the largest coefficients\n",
    "coe_cat_dict={}\n",
    "coe_num_dict={} #feature name as keys!##\n",
    "coe_num = coefficients[:len(Numeric_columns)]\n",
    "coe_cat = coefficients[len(Numeric_columns):]\n",
    "\n",
    "for i in range(len(coe_cat)):\n",
    "    coe_cat_dict[i] = coe_cat[i]\n",
    "    \n",
    "for i in range(len(coe_num)):\n",
    "    coe_num_dict[str(Numeric_columns[i])] = coe_num[i]\n",
    "    \n",
    "#get aggregated coe_cat using previous helper function\n",
    "coe_cat_aggre = pmi_aggr(coe_cat_dict)\n",
    "all_features_coe_dict = dict(coe_num_dict, **coe_cat_aggre)\n",
    "\n",
    "#find two features with largest coefficients\n",
    "sorted_coe = sorted(all_features_coe_dict, key=all_features_coe_dict.get, reverse=True)\n",
    "f1_largest_coe = sorted_coe[0]\n",
    "f2_2nd_largest_coe = sorted_coe[1]\n",
    "\n",
    "\n",
    "############################\n",
    "## your code ends here\n",
    "############################\n",
    "\n",
    "print(f\"LR predicted class distribution\\t {Counter(lr_predictions)}\")\n",
    "print(\"\\n\")\n",
    "#answers for Q5b part1\n",
    "print(f\"pmi values in Q3: {pmi_aggregate}\")\n",
    "print(\"\\n\")\n",
    "print(f\"coefficient values in Q5a: {all_features_coe_dict}\")\n",
    "print(\"\\n\")\n",
    "#answers for Q5b part2\n",
    "print(f\"The feature with the largest coefficients is: {f1_largest_coe}\")\n",
    "print(f\"The feature with the second largest coefficients is {f2_2nd_largest_coe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Evaluation\n",
    "\n",
    "We will evaluate our baselines and classifiers on the instances in the test set. \n",
    "\n",
    "Compute \n",
    "- accuracy\n",
    "- macro-averaged F1 score \n",
    "\n",
    "for the two baselines, the three NB classifiers and the LR classifier.\n",
    "\n",
    "**You may use existing implementations and/or Python libraries like numpy, scipy or sklearn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero R\t\tAccuracy: 0.76\tMacro F1: 0.43\n",
      "One  R\t\tAccuracy: 0.77\tMacro F1: 0.5\n",
      "NB Num \t\tAccuracy: 0.8\tMacro F1: 0.64\n",
      "NB Cat \t\tAccuracy: 0.76\tMacro F1: 0.72\n",
      "NB Full \tAccuracy: 0.83\tMacro F1: 0.75\n",
      "LR \t\tAccuracy: 0.8\tMacro F1: 0.63\n"
     ]
    }
   ],
   "source": [
    "zero_r_acc = 0\n",
    "zero_r_f1 = 0\n",
    "\n",
    "one_r_acc = 0\n",
    "one_r_f1 = 0\n",
    "\n",
    "num_nb_acc = 0\n",
    "num_nb_f1 = 0\n",
    "\n",
    "cat_nb_acc = 0\n",
    "cat_nb_f1 = 0\n",
    "\n",
    "full_nb_acc = 0\n",
    "full_nb_f1 = 0\n",
    "\n",
    "lr_acc = 0\n",
    "lr_f1 = 0\n",
    "\n",
    "############################\n",
    "## your code begins here\n",
    "############################\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def accuracy(predict, test_label):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    \n",
    "    for i in range(len(test_label)):\n",
    "        if (test_label[i] == '>50K') and (predict[i] == '>50K'):\n",
    "            TP += 1\n",
    "        elif (test_label[i] == '<=50K') and (predict[i] == '>50K'):\n",
    "            FN += 1\n",
    "        elif (test_label[i] == '<=50K') and (predict[i] == '<=50K'):\n",
    "            TN += 1\n",
    "        elif (test_label[i] == '>50K') and (predict[i] == '<=50K'):\n",
    "            FP += 1\n",
    "        \n",
    "    accuracy = (TP + TN) / (TP + FN + FP + TN)\n",
    "    return accuracy\n",
    "\n",
    "zero_r_acc = accuracy(zero_r_predictions, y_test)\n",
    "zero_r_f1 = f1_score(y_test, zero_r_predictions, average='macro')\n",
    "\n",
    "one_r_acc = accuracy(one_r_predictions, y_test)\n",
    "one_r_f1 = f1_score(y_test, one_r_predictions, average='macro')\n",
    "\n",
    "num_nb_acc = accuracy(numeric_nb_predictions, y_test)\n",
    "num_nb_f1 = f1_score(y_test, numeric_nb_predictions, average='macro')\n",
    "\n",
    "cat_nb_acc = accuracy(categorical_nb_predictions, y_test)\n",
    "cat_nb_f1 = f1_score(y_test, categorical_nb_predictions, average='macro')\n",
    "\n",
    "full_nb_acc = accuracy(full_nb_predictions, y_test)\n",
    "full_nb_f1 = f1_score(y_test, full_nb_predictions, average='macro')\n",
    "\n",
    "lr_acc = accuracy(lr_predictions, y_test)\n",
    "lr_f1 = f1_score(y_test, lr_predictions, average='macro')\n",
    "\n",
    "############################\n",
    "## your code ends here\n",
    "############################\n",
    "\n",
    "print(f\"Zero R\\t\\tAccuracy: {round(zero_r_acc, 2)}\\tMacro F1: {round(zero_r_f1, 2)}\")\n",
    "print(f\"One  R\\t\\tAccuracy: {round(one_r_acc, 2)}\\tMacro F1: {round(one_r_f1, 2)}\")\n",
    "print(f\"NB Num \\t\\tAccuracy: {round(num_nb_acc, 2)}\\tMacro F1: {round(num_nb_f1, 2)}\")\n",
    "print(f\"NB Cat \\t\\tAccuracy: {round(cat_nb_acc, 2)}\\tMacro F1: {round(cat_nb_f1, 2)}\")\n",
    "print(f\"NB Full \\tAccuracy: {round(full_nb_acc, 2)}\\tMacro F1: {round(full_nb_f1, 2)}\")\n",
    "print(f\"LR \\t\\tAccuracy: {round(lr_acc, 2)}\\tMacro F1: {round(lr_f1, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
